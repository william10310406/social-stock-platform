#!/usr/bin/env python3
# -*- coding: utf-8 -*-

"""
è‚¡ç¥¨è³‡æ–™å°å‡ºç‚º JSON æ ¼å¼çš„è…³æœ¬
Stock data export to JSON format script
"""

import os
import sys
import json
import pyodbc
from datetime import datetime
from typing import List, Dict, Any

# æ·»åŠ é …ç›®æ ¹ç›®éŒ„åˆ°è·¯å¾‘ï¼ˆå‹•æ…‹ç²å–ï¼‰
project_root = os.path.dirname(os.path.dirname(os.path.abspath(__file__)))
sys.path.append(os.path.join(project_root, 'backend'))

try:
    from scripts.script_env import ScriptEnvironment
    env = ScriptEnvironment()
    config = env.get_environment_info()['config']
except ImportError:
    # å‚™ç”¨é…ç½®ï¼ˆå¦‚æœç„¡æ³•å°å…¥ç’°å¢ƒæ¨¡çµ„ï¼‰
    is_docker = os.getenv('DOCKER_ENV') == 'true' or os.path.exists('/.dockerenv')
    config = {
        'database': {
            'host': os.getenv('DB_HOST', 'stock-insight-db' if is_docker else '127.0.0.1'),
            'name': os.getenv('MSSQL_DATABASE', 'StockInsight'),
            'user': os.getenv('MSSQL_USER', 'sa'),
            'password': os.getenv('MSSQL_SA_PASSWORD', 'StrongPassword123!')
        }
    }

def get_db_connection():
    """ç²å–è³‡æ–™åº«é€£æ¥"""
    try:
        # ä½¿ç”¨çµ±ä¸€ç’°å¢ƒé…ç½®
        db_config = config['database']
        server = db_config['host']
        database = db_config['name']
        username = db_config['user']
        password = db_config['password']
        
        # æ§‹å»ºé€£æ¥å­—ç¬¦ä¸²
        conn_str = f"""
        DRIVER={{ODBC Driver 18 for SQL Server}};
        SERVER={server};
        DATABASE={database};
        UID={username};
        PWD={password};
        TrustServerCertificate=yes;
        """
        
        connection = pyodbc.connect(conn_str)
        return connection
    except Exception as e:
        print(f"âŒ è³‡æ–™åº«é€£æ¥å¤±æ•—: {e}")
        return None

def export_stocks_to_json(output_dir: str) -> bool:
    """å°å‡ºè‚¡ç¥¨è³‡æ–™ç‚º JSON æ ¼å¼"""
    try:
        # ç²å–è³‡æ–™åº«é€£æ¥
        conn = get_db_connection()
        if not conn:
            return False
        
        cursor = conn.cursor()
        
        # æŸ¥è©¢æ‰€æœ‰è‚¡ç¥¨è³‡æ–™
        query = """
        SELECT 
            id,
            symbol,
            name,
            exchange,
            market_type,
            created_at,
            updated_at
        FROM Stocks
        ORDER BY symbol
        """
        
        cursor.execute(query)
        rows = cursor.fetchall()
        
        # è½‰æ›ç‚ºå­—å…¸åˆ—è¡¨
        stocks_data = []
        for row in rows:
            stock = {
                "id": row.id,
                "symbol": row.symbol,
                "name": row.name,
                "exchange": row.exchange,
                "market_type": row.market_type,
                "created_at": row.created_at.isoformat() if row.created_at else None,
                "updated_at": row.updated_at.isoformat() if row.updated_at else None
            }
            stocks_data.append(stock)
        
        # å‰µå»ºå°å‡ºçš„å…ƒæ•¸æ“š
        export_metadata = {
            "export_time": datetime.now().isoformat(),
            "total_stocks": len(stocks_data),
            "source_database": "StockInsight",
            "format_version": "1.0"
        }
        
        # æŒ‰äº¤æ˜“æ‰€åˆ†é¡çµ±è¨ˆ
        exchange_stats = {}
        market_type_stats = {}
        
        for stock in stocks_data:
            # çµ±è¨ˆäº¤æ˜“æ‰€
            exchange = stock["exchange"] or "æœªçŸ¥"
            exchange_stats[exchange] = exchange_stats.get(exchange, 0) + 1
            
            # çµ±è¨ˆå¸‚å ´é¡å‹
            market_type = stock["market_type"] or "ä¸€èˆ¬"
            market_type_stats[market_type] = market_type_stats.get(market_type, 0) + 1
        
        # å®Œæ•´çš„å°å‡ºçµæ§‹
        export_data = {
            "metadata": export_metadata,
            "statistics": {
                "by_exchange": exchange_stats,
                "by_market_type": market_type_stats
            },
            "stocks": stocks_data
        }
        
        # ç¢ºä¿è¼¸å‡ºç›®éŒ„å­˜åœ¨
        os.makedirs(output_dir, exist_ok=True)
        
        # å¯«å…¥å®Œæ•´çš„ JSON æ–‡ä»¶
        full_json_path = os.path.join(output_dir, "stocks_complete.json")
        with open(full_json_path, 'w', encoding='utf-8') as f:
            json.dump(export_data, f, ensure_ascii=False, indent=2)
        
        # å¯«å…¥ç°¡åŒ–çš„è‚¡ç¥¨åˆ—è¡¨ JSON
        simple_json_path = os.path.join(output_dir, "stocks_simple.json")
        with open(simple_json_path, 'w', encoding='utf-8') as f:
            json.dump(stocks_data, f, ensure_ascii=False, indent=2)
        
        # å¯«å…¥çµ±è¨ˆè³‡æ–™ JSON
        stats_json_path = os.path.join(output_dir, "stocks_statistics.json")
        stats_data = {
            "metadata": export_metadata,
            "statistics": {
                "total_stocks": len(stocks_data),
                "by_exchange": exchange_stats,
                "by_market_type": market_type_stats
            }
        }
        with open(stats_json_path, 'w', encoding='utf-8') as f:
            json.dump(stats_data, f, ensure_ascii=False, indent=2)
        
        conn.close()
        
        print(f"âœ… JSON å°å‡ºæˆåŠŸ!")
        print(f"ğŸ“ å°å‡ºç›®éŒ„: {output_dir}")
        print(f"ğŸ“„ å®Œæ•´è³‡æ–™: {full_json_path}")
        print(f"ğŸ“„ ç°¡åŒ–åˆ—è¡¨: {simple_json_path}")
        print(f"ğŸ“„ çµ±è¨ˆè³‡æ–™: {stats_json_path}")
        print(f"ğŸ“Š ç¸½è‚¡ç¥¨æ•¸: {len(stocks_data)}")
        
        return True
        
    except Exception as e:
        print(f"âŒ JSON å°å‡ºå¤±æ•—: {e}")
        return False

if __name__ == "__main__":
    if len(sys.argv) < 2:
        print("ä½¿ç”¨æ–¹æ³•: python export_stocks_to_json.py <è¼¸å‡ºç›®éŒ„>")
        sys.exit(1)
    
    output_directory = sys.argv[1]
    success = export_stocks_to_json(output_directory)
    sys.exit(0 if success else 1) 