#!/bin/bash

# Stock Insight Platform - ä¿®å¾©ç‰ˆå°å‡ºè…³æœ¬ v2
# è§£æ±º SQL è¼¸å‡ºæ··å…¥ã€æ ¼å¼å•é¡Œå’Œ CSV è¡¨é ­å•é¡Œ

set -e

# é…ç½®
TIMESTAMP=$(date -u +"%Y%m%d_%H%M%S")
EXPORT_DIR="exports/stocks_fixed_v2_${TIMESTAMP}"
DB_CONTAINER="stock-insight-db"
DATABASE="StockInsight"

echo "ğŸ”§ Stock Insight Platform - ä¿®å¾©ç‰ˆæ•¸æ“šå°å‡º v2"
echo "==============================================="
echo "å°å‡ºæ™‚é–“: $(date -u +"%Y-%m-%d %H:%M:%S UTC")"
echo "å°å‡ºç›®éŒ„: ${EXPORT_DIR}"
echo ""

# å‰µå»ºå°å‡ºç›®éŒ„
mkdir -p "${EXPORT_DIR}"
cd "${EXPORT_DIR}"

echo "ğŸ“Š æ­£åœ¨å°å‡ºè‚¡ç¥¨è³‡æ–™..."

# 1. ç´”æ•¸æ“š CSV å°å‡ºï¼ˆå»é™¤è¡¨é ­å’Œåˆ†éš”ç·šï¼‰
echo "   â†’ å°å‡º CSV è³‡æ–™"
docker exec "${DB_CONTAINER}" /opt/mssql-tools18/bin/sqlcmd \
    -S localhost -U sa -P "StrongPassword123!" \
    -d "${DATABASE}" -C \
    -Q "SET NOCOUNT ON; SELECT id,symbol,name,exchange,market_type,created_at,updated_at FROM stocks ORDER BY id;" \
    -s "," -W -h -1 > stocks_clean.csv

# æ¸…ç† CSVï¼ˆç§»é™¤ç©ºè¡Œã€SQL è¼¸å‡ºå’Œè¡¨é ­åˆ†éš”ç·šï¼‰
grep -v "^$" stocks_clean.csv | grep -v "Changed database" | grep -v "rows affected" | grep -v "^--" | grep -v "^id,symbol" > stocks_data.csv

echo "   â†’ å°å‡ºçµ±è¨ˆè³‡æ–™"
# 2. çµ±è¨ˆè³‡æ–™å°å‡º
docker exec "${DB_CONTAINER}" /opt/mssql-tools18/bin/sqlcmd \
    -S localhost -U sa -P "StrongPassword123!" \
    -d "${DATABASE}" -C \
    -Q "SET NOCOUNT ON; 
        SELECT 'ç¸½è‚¡ç¥¨æ•¸', COUNT(*) FROM stocks UNION ALL
        SELECT 'ä¸Šå¸‚è‚¡ç¥¨', COUNT(*) FROM stocks WHERE exchange='ä¸Šå¸‚' UNION ALL
        SELECT 'ä¸Šæ«ƒè‚¡ç¥¨', COUNT(*) FROM stocks WHERE exchange='ä¸Šæ«ƒ' UNION ALL
        SELECT 'å‰µæ–°æ¿', COUNT(*) FROM stocks WHERE market_type='å‰µæ–°æ¿' UNION ALL
        SELECT 'KYè‚¡', COUNT(*) FROM stocks WHERE market_type='KY';" \
    -s "," -W -h -1 > stats_raw.csv

# æ¸…ç†çµ±è¨ˆè³‡æ–™
grep -v "^$" stats_raw.csv | grep -v "Changed database" | grep -v "rows affected" | grep -v "^--" > statistics.csv

echo "   â†’ ç”Ÿæˆ JSON æ ¼å¼"
# 3. ç”Ÿæˆæ¨™æº– JSON æ ¼å¼ï¼ˆæ”¹é€²ç‰ˆï¼‰
cat > generate_json.py << 'EOF'
import csv
import json
import sys
from datetime import datetime

def create_json_export():
    try:
        # è®€å–è‚¡ç¥¨æ•¸æ“š
        stocks = []
        with open('stocks_data.csv', 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) >= 7 and row[0].isdigit():  # ç¢ºä¿æ˜¯æœ‰æ•ˆçš„æ•¸æ“šè¡Œ
                    stocks.append({
                        "id": int(row[0]),
                        "symbol": row[1].strip(),
                        "name": row[2].strip(),
                        "exchange": row[3].strip(),
                        "market_type": row[4].strip() if row[4].strip() != 'NULL' else None,
                        "created_at": row[5].strip(),
                        "updated_at": row[6].strip()
                    })
        
        # è®€å–çµ±è¨ˆæ•¸æ“š
        stats = {}
        with open('statistics.csv', 'r', encoding='utf-8') as f:
            reader = csv.reader(f)
            for row in reader:
                if len(row) >= 2 and row[1].isdigit():  # ç¢ºä¿æ˜¯æœ‰æ•ˆçš„çµ±è¨ˆè¡Œ
                    stats[row[0].strip()] = int(row[1])
        
        # å‰µå»º JSON çµæ§‹
        json_data = {
            "metadata": {
                "export_time": datetime.utcnow().isoformat() + "Z",
                "source_database": "StockInsight",
                "format_version": "2.0",
                "total_records": len(stocks)
            },
            "statistics": stats,
            "stocks": stocks
        }
        
        # å¯«å…¥ JSON æ–‡ä»¶
        with open('stocks_complete.json', 'w', encoding='utf-8') as f:
            json.dump(json_data, f, ensure_ascii=False, indent=2)
        
        print(f"âœ… æˆåŠŸç”Ÿæˆ JSONï¼ŒåŒ…å« {len(stocks)} æ”¯è‚¡ç¥¨")
        
        # é¡¯ç¤ºçµ±è¨ˆè³‡è¨Š
        print("ğŸ“Š çµ±è¨ˆè³‡è¨Š:")
        for key, value in stats.items():
            print(f"   â€¢ {key}: {value}")
        
    except Exception as e:
        print(f"âŒ JSON ç”ŸæˆéŒ¯èª¤: {e}")
        sys.exit(1)

if __name__ == "__main__":
    create_json_export()
EOF

# åŸ·è¡Œ JSON ç”Ÿæˆ
python3 generate_json.py

echo "   â†’ å‰µå»ºè³‡æ–™åº«å‚™ä»½"
# 4. æ•¸æ“šåº«å‚™ä»½
docker exec "${DB_CONTAINER}" /opt/mssql-tools18/bin/sqlcmd \
    -S localhost -U sa -P "StrongPassword123!" -C \
    -Q "BACKUP DATABASE [${DATABASE}] TO DISK = '/var/opt/mssql/data/StockInsight_Fixed_v2_Export.bak' 
        WITH FORMAT, INIT, NAME = 'StockInsight Fixed v2 Export', SKIP, NOREWIND, NOUNLOAD;"

# è¤‡è£½å‚™ä»½æ–‡ä»¶
docker cp "${DB_CONTAINER}:/var/opt/mssql/data/StockInsight_Fixed_v2_Export.bak" ./

echo ""
echo "ğŸ“‹ å°å‡ºå®Œæˆå ±å‘Š"
echo "==================="
echo "å°å‡ºç›®éŒ„: ${EXPORT_DIR}"
echo ""

# æª¢æŸ¥æ–‡ä»¶ä¸¦é¡¯ç¤ºå¤§å°
if [ -f "stocks_data.csv" ]; then
    STOCK_COUNT=$(wc -l < stocks_data.csv)
    FILE_SIZE=$(du -h stocks_data.csv | cut -f1)
    echo "âœ… stocks_data.csv - ${STOCK_COUNT} æ”¯è‚¡ç¥¨ (${FILE_SIZE})"
fi

if [ -f "stocks_complete.json" ]; then
    FILE_SIZE=$(du -h stocks_complete.json | cut -f1)
    echo "âœ… stocks_complete.json - JSON æ ¼å¼ (${FILE_SIZE})"
fi

if [ -f "StockInsight_Fixed_v2_Export.bak" ]; then
    FILE_SIZE=$(du -h StockInsight_Fixed_v2_Export.bak | cut -f1)
    echo "âœ… StockInsight_Fixed_v2_Export.bak - è³‡æ–™åº«å‚™ä»½ (${FILE_SIZE})"
fi

echo ""
echo "ğŸ¯ ä¿®å¾©å®Œæˆï¼æ‰€æœ‰æ–‡ä»¶å·²æ¸…ç†ä¸¦æ ¼å¼åŒ–æ­£ç¢ºã€‚"
echo "ğŸ“ æ”¹é€²é …ç›®ï¼š"
echo "  â€¢ ç§»é™¤ CSV è¡¨é ­å’Œåˆ†éš”ç·š"
echo "  â€¢ æ™ºèƒ½æ•¸æ“šé©—è­‰"
echo "  â€¢ å®Œæ•´çµ±è¨ˆè³‡è¨Š"
echo "  â€¢ æ¨™æº– JSON æ ¼å¼"
echo ""
echo "ğŸ“ æ–‡ä»¶èªªæ˜ï¼š"
echo "  - stocks_data.csv: ç´”æ·¨çš„ CSV æ•¸æ“šï¼Œç„¡è¡¨é ­ç„¡åˆ†éš”ç·š"
echo "  - stocks_complete.json: å®Œæ•´ JSON æ ¼å¼ï¼ŒåŒ…å«å…ƒæ•¸æ“šå’Œçµ±è¨ˆ"
echo "  - StockInsight_Fixed_v2_Export.bak: å®Œæ•´è³‡æ–™åº«å‚™ä»½"

# æ¸…ç†è‡¨æ™‚æ–‡ä»¶
rm -f stocks_clean.csv stats_raw.csv generate_json.py

cd - > /dev/null
echo ""
echo "å°å‡ºè·¯å¾‘: $(pwd)/${EXPORT_DIR}" 